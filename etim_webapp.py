import logging
logging.basicConfig(level=logging.DEBUG)

import streamlit as st
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import fitz  # PyMuPDF per leggere PDF
import requests
from bs4 import BeautifulSoup
from sentence_transformers import SentenceTransformer

# === ETIM setup ===
@st.cache_data
def load_etim_data():
    df = pd.read_excel("Classi_9.xlsx")

    required_cols = ['Code', 'Description (EN)', 'ETIM IT',
                     'Translation (ETIM CH)', 'Traduttore Google',
                     'Traduzione_DEF', 'Sinonimi']

    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        st.error(f"âŒ Mancano queste colonne nel file Excel: {missing}")
        st.stop()

    df = df[required_cols].fillna('')
    righe_senza_sinonimi = df[df['Sinonimi'].str.strip() == '']
    if not righe_senza_sinonimi.empty:
        st.warning(f"ğŸ” Attenzione: {len(righe_senza_sinonimi)} classi non hanno sinonimi. Considera di arricchirle per migliorare la precisione.")

    df['combined_text'] = df.apply(lambda row: ' '.join([
        row['Description (EN)'], row['ETIM IT'], row['Translation (ETIM CH)'],
        row['Traduttore Google'], row['Traduzione_DEF'], row['Sinonimi']
    ]).lower(), axis=1)
    return df

@st.cache_resource
def load_semantic_model():
    return SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')

from transformers import pipeline

@st.cache_resource
def load_paraphraser():
    return pipeline("text2text-generation", model="google/flan-t5-base")

def classify_semantic_top_k(description, df, model, top_k=5):
    corpus = df['combined_text'].tolist()
    corpus_embeddings = model.encode(corpus, convert_to_tensor=True)
    input_embedding = model.encode(description, convert_to_tensor=True)
    similarities = cosine_similarity([input_embedding.cpu().numpy()], corpus_embeddings.cpu().numpy()).flatten()
    top_indices = similarities.argsort()[-top_k:][::-1]
    results = df.iloc[top_indices].copy()
    results["Confidence"] = [round(similarities[i] * 100, 2) for i in top_indices]
    return results

# === Streamlit app ===
st.set_page_config(page_title="Classificatore ETIM", layout="centered")
st.title("ğŸ¤– Classificatore automatico ETIM da testo, PDF o URL")
st.markdown("Inserisci una **descrizione**, carica un **PDF** o incolla un **link** per identificare la classe ETIM.")

# Caricamento dati
df_etim = load_etim_data()
semantic_model = load_semantic_model()

# Input libero
user_input = st.text_area("ğŸ“Œ Oppure inserisci direttamente la descrizione del prodotto:", height=150)

# Caricamento PDF
pdf_file = st.file_uploader("ğŸ“ Carica una scheda tecnica in PDF (facoltativo):", type="pdf")
if pdf_file:
    try:
    with st.spinner("Sto analizzando il significato della descrizione..."):
        paraphraser = load_paraphraser()
        refined = paraphraser(user_input, max_length=100, do_sample=False)[0]['generated_text']
        st.markdown(f"âœï¸ Descrizione interpretata dall'AI: _{refined}_")
        user_input = refined
except Exception as e:
    st.error(f"âŒ Errore durante lâ€™analisi semantica: {e}")


# Inserimento URL
url_input = st.text_input("ğŸ”— Oppure incolla un link a una scheda prodotto online:")
if url_input:
    try:
        response = requests.get(url_input, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        paragraphs = soup.find_all(['p', 'h1', 'h2', 'li'])
        text = ' '.join(p.get_text() for p in paragraphs if len(p.get_text()) > 30)
        user_input = text.strip()
        if len(user_input) < 50:
            st.warning("âš ï¸ Attenzione: il testo estratto dal link Ã¨ molto breve e potrebbe non essere sufficiente.")
        st.text_area("ğŸ§¾ Testo estratto dalla pagina:", value=user_input[:2000], height=150)
    except Exception as e:
        st.error(f"Errore nel caricamento della pagina: {e}")

# Classificazione finale
if st.button("Classifica"):
    user_input = user_input.strip()
    # ğŸ§  Parafrasi del testo con modello HuggingFace
    with st.spinner("Sto analizzando il significato della descrizione..."):
            paraphraser = load_paraphraser()
            refined = paraphraser(user_input, max_length=100, do_sample=False)[0]['generated_text']
            st.markdown(f"âœï¸ Descrizione interpretata dall'AI: _{refined}_")
            user_input = refined
    if user_input:
        st.markdown("ğŸ§  Testo analizzato dall'AI:")
        st.code(user_input[:600])
        top_results = classify_semantic_top_k(user_input, df_etim, semantic_model, top_k=5)

        if top_results.empty:
            st.error("âŒ Nessuna classe suggerita. Potresti arricchire i sinonimi nel file Excel.")
        else:
            st.success("âœ… Classi ETIM suggerite:")
            for _, row in top_results.iterrows():
                st.markdown(f"**{row['Code']}** â€“ {row['ETIM IT']}")
                st.markdown(f"ğŸ”¤ Descrizione (EN): {row['Description (EN)']}")
                st.markdown(f"ğŸ“ˆ Confidenza AI: {row['Confidence']}%")
                st.markdown("---")
    else:
        st.warning("Inserisci una descrizione, carica un PDF o un link.")
